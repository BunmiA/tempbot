<!DOCTYPE html>
<html lang="en">
<!--<script src="opencv.js"></script>-->
<head>
    <meta charset="UTF-8">
    <title>Title</title>
</head>

<body>
<video style=" border-style: solid;" autoplay="true" id="videoInput" width="320" height="240"></video>
<canvas style=" border-style: solid; border-color: deeppink" id="canvasOutput" width="320" height="240"></canvas>
<p id="errorMessage"></p>

</body>
<script src="utils.js" type="text/javascript"></script>
<script type="text/javascript">
    let video = document.getElementById('videoInput');
    if (navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia({video: true})
            .then(function (stream) {
                video.srcObject = stream;
            })
            .catch(function (error) {
                console.log(error);
                console.log("Something went wrong with stream!");
            });
    }

    let utils = new Utils('errorMessage'); //use utils class
    utils.loadOpenCv(openCvReady);


    // let streaming = true
    //todo better understand the loading
    function openCvReady() {
        let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
        let dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
        let gray = new cv.Mat();
        let cap = new cv.VideoCapture(video);
        let faces = new cv.RectVector();
        let classifier = new cv.CascadeClassifier();
        let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to xml ad

        // load pre-trained classifiers
        // classifier.load(faceCascadeFile);
        utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
            //console.log(faceCascadeFile)
            classifier.load(faceCascadeFile); // in the callback, load the cascade from file
            console.log("xml is ready")


            let streaming = true
            const FPS = 30;

            function processVideo() {
                try {
                    // if (!streaming) {
                    //     // clean and stop.
                    //     src.delete();
                    //     dst.delete();
                    //     gray.delete();
                    //     faces.delete();
                    //     classifier.delete();
                    //     return;
                    // }
                    let begin = Date.now();
                    // start processing.
                    cap.read(src);
                    src.copyTo(dst);
                    cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);

                    // detect faces.
                    //classifier.detectMultiScale(gray, faces, 1.1, 3, 0);

                    classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
                    //face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')
                    // draw faces.
                    for (let i = 0; i < faces.size(); ++i) {
                        let face = faces.get(i);
                        let point1 = new cv.Point(face.x, face.y);
                        let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                        cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
                    }
                    cv.imshow('canvasOutput', dst);

                    // schedule the next one.
                    let delay = 1000 / FPS - (Date.now() - begin);
                    setTimeout(processVideo, delay);
                } catch (err) {
                    utils.printError(err);
                }
            };
            // schedule the first one.
            setTimeout(processVideo, 0);
        });
    };

</script>
</html>